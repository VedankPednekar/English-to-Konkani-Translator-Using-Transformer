{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gjy8_r22R_DK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-24 14:12:58.562883: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-24 14:12:58.574605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742825578.587368    2087 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742825578.590933    2087 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-24 14:12:58.604455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wo_kGNkSGTH",
        "outputId": "4def2571-cc59-48b3-e8f2-4d09be6d188e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide the following details accurately\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Please provide the following details accurately\\n\")\n",
        "\n",
        "path_data = os.path.abspath(input(\"Relative path to the Dataset: \"))\n",
        "\n",
        "vocab_size = input(\"Enter max vocabulary size (press enter to leave to default 40,000): \").strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PDG3Bj0ESGOU"
      },
      "outputs": [],
      "source": [
        "if vocab_size is None or vocab_size.isnumeric() == False:\n",
        "    vocab_size = 40000\n",
        "else:\n",
        "    vocab_size = int(vocab_size)\n",
        "\n",
        "path_vocab=os.path.abspath(path_data+'.vocab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ee0BeIgJSGLd"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    \n",
        "    with open(path, encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        \n",
        "        len_data=len(lines)\n",
        "        context = np.empty(shape=len_data,dtype=object)\n",
        "        i=0\n",
        "        for line in lines:\n",
        "            context[i] = line\n",
        "            i+=1\n",
        "    del lines\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LewbqJ-3SGJG"
      },
      "outputs": [],
      "source": [
        "\n",
        "target_full_raw = load_data(path_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h9PEMS4xSF82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742825591.105316    2087 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "#convert to tensor\n",
        "full_en = tf.data.Dataset.from_tensor_slices(target_full_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fQoUUjXvSSyr"
      },
      "outputs": [],
      "source": [
        "bert_tokenizer_params=dict(lower_case=False)\n",
        "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R3kx3wCVSSrh"
      },
      "outputs": [],
      "source": [
        "bert_vocab_args = dict(\n",
        "    # The target vocabulary size\n",
        "    vocab_size = vocab_size,\n",
        "    # Reserved tokens that must be included in the vocabulary\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    # Arguments for `text.BertTokenizer`\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "    learn_params={},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLG52265SSiM",
        "outputId": "102755c4-c5ca-4c58-e840-46c99fc16316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building Vocabulary, This may take some time...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-24 14:13:13.034753: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary build complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"Building Vocabulary, This may take some time...\")\n",
        "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    full_en.batch(1000).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")\n",
        "print(\"Vocabulary build complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfA9TUDFSglL",
        "outputId": "f69c24f7-28c6-4960-e0fb-4029315e4b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "length of vocabulary: 33593\n",
            "Examples:\n",
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', '\"', '#', '$', '%', '&']\n",
            "['÷', '˚', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ']\n",
            "['बाजारांत', 'वाट', 'आडमेळीं', 'हाच्या', 'तरेकवार', 'हात', 'पद्दतींत', 'पळोवपा', 'कर्मचारी', '##खातीर']\n",
            "['##ढ़', '##फ़', '##य़', '##ॠ', '##।', '##ॲ', '##“', '##”', '##…', '##⅓']\n"
          ]
        }
      ],
      "source": [
        "en_vocab_size = len(en_vocab)\n",
        "\n",
        "print()\n",
        "print(\"length of vocabulary:\",en_vocab_size)\n",
        "print(\"Examples:\")\n",
        "print(en_vocab[:10])\n",
        "print(en_vocab[100:110])\n",
        "print(en_vocab[1000:1010])\n",
        "print(en_vocab[-10:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tFNmWumzSjbV"
      },
      "outputs": [],
      "source": [
        "#write vocab to file\n",
        "def write_vocab_file(filepath, vocab):\n",
        "  with open(filepath, 'w') as f:\n",
        "    for token in vocab:\n",
        "      print(token, file=f)\n",
        "\n",
        "write_vocab_file(path_vocab, en_vocab)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
